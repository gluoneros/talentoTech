{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMr3TLoE2lhX"
      },
      "source": [
        "# NLP (Natural Language Processing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CX1xbNAbbgFx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/usuario/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "STOPWORDS = set(stopwords.words('spanish'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0hszmeTjchk"
      },
      "source": [
        "Tokenización"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg4bpoYejlth"
      },
      "source": [
        "* Ejemplo sin tokenizar: La casa es azul y es una casa\n",
        "* Ejemplo tokenizado: ['la', 'casa', 'es', 'y', 'una', 'azul']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /home/usuario/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = \"El perro corre rápido y es un perro\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYSKmbuE5o5_",
        "outputId": "f5d86345-562c-4066-bd34-cc85f1ca2e0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['El', 'perro', 'corre', 'rápido', 'y', 'es', 'un', 'perro']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjEigc2WbLT3"
      },
      "source": [
        "Normalización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HLOyJFe9bZ1U",
        "outputId": "05b74fbb-1999-4ad6-8620-30dea7816cc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "el perro corre rápido\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "texto = \"El PERRO corre RÁPIDO!!!\"\n",
        "texto_normalizado = re.sub(r'[^\\w\\s]', '', texto.lower())\n",
        "print(texto_normalizado)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LP69RYbTbNAX"
      },
      "source": [
        "Eliminar Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jc0VBA2bs_e",
        "outputId": "9455f7d6-6e41-414c-bcff-8be272a04862"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['perro', 'corre', 'rápido']\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /home/usuario/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "texto = \"El perro corre rápido\"\n",
        "stop_words = set(stopwords.words('spanish'))\n",
        "tokens = word_tokenize(texto.lower())\n",
        "tokens_filtrados = [word for word in tokens if word not in stop_words]\n",
        "print(tokens_filtrados)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1EqKAwsdbRiB"
      },
      "source": [
        "Lematización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kyz9o7DtcUnr",
        "outputId": "e42fc274-0fc8-458a-d4e9-1d4657390b14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting es-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/es_core_news_sm-3.8.0/es_core_news_sm-3.8.0-py3-none-any.whl (12.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('es_core_news_sm')\n"
          ]
        }
      ],
      "source": [
        "!python -m spacy download es_core_news_sm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEe9SpMbbxBY",
        "outputId": "2ef48231-73ad-41e3-bc1a-3b3ba6169528"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['el', 'perro', 'estar', 'correr', 'rápido']\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('es_core_news_sm')\n",
        "\n",
        "texto = \"El perro está corriendo rápido\"\n",
        "\n",
        "doc = nlp(texto)\n",
        "\n",
        "tokens_lemantizados = [token.lemma_ for token in doc]\n",
        "print(tokens_lemantizados)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjS_mKGZbTxQ"
      },
      "source": [
        "Steamming"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aHVFxvkkcbPo",
        "outputId": "a09dd2e2-e4a8-4477-b866-c0c3c37e6902"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['el', 'perr', 'esta', 'corr', 'rap']\n"
          ]
        }
      ],
      "source": [
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "stemmer = SnowballStemmer('spanish')\n",
        "texto = \"El perro está corriendo rápido\"\n",
        "tokens = word_tokenize(texto.lower())\n",
        "\n",
        "# Aplicar stemming\n",
        "tokens_stemmed = [stemmer.stem(token) for token in tokens]\n",
        "print(tokens_stemmed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYOs3ntmf1yG"
      },
      "source": [
        "## Representación / Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhO4flqIbWFf"
      },
      "source": [
        "Bolsa de Palabras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BujIU_tQdA_I",
        "outputId": "2679f3d3-ab99-4d53-9b18-2ed51477a420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['corre' 'el' 'gato' 'perro' 'rápido']\n",
            "[[1 1 0 1 1]\n",
            " [1 1 1 0 1]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "textos = [\"el perro corre rápido\", \"el gato corre rápido\"]\n",
        "vectorizer = CountVectorizer()\n",
        "X = vectorizer.fit_transform(textos)\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8_McGLabY1d"
      },
      "source": [
        "TF-IDF (Term Frequency-Inverse Document Frequency)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxpeE2EydVhe",
        "outputId": "4939c5e6-d253-4349-f25a-5970ca4d987d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['corre' 'el' 'gato' 'perro' 'rápido']\n",
            "[[0.44832087 0.44832087 0.         0.63009934 0.44832087]\n",
            " [0.44832087 0.44832087 0.63009934 0.         0.44832087]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "textos = [\"el perro corre rápido\", \"el gato corre rápido\"]\n",
        "vectorizer = TfidfVectorizer()\n",
        "X = vectorizer.fit_transform(textos)\n",
        "\n",
        "print(vectorizer.get_feature_names_out())\n",
        "print(X.toarray())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTDje01aSNyD"
      },
      "source": [
        "# The Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "6Xh1Oco_wg8t",
        "outputId": "80f033a9-612a-41fb-e4ef-a3790f8083b0"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label                                        sms_message\n",
              "0      ham  Go until jurong point, crazy.. Available only ...\n",
              "1      ham                      Ok lar... Joking wif u oni...\n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      ham  U dun say so early hor... U c already then say...\n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
              "...    ...                                                ...\n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
              "5568   ham              Will Ì_ b going to esplanade fr home?\n",
              "5569   ham  Pity, * was in mood for that. So...any other s...\n",
              "5570   ham  The guy did some bitching but I acted like i'd...\n",
              "5571   ham                         Rofl. Its true to its name\n",
              "\n",
              "[5572 rows x 2 columns]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "\n",
        "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
        "data = data.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1)\n",
        "data.columns = ['label', 'sms_message']\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "SLaqIqVuwu-b",
        "outputId": "3cbb5d45-3c89-4985-aacf-0ff94d6200fb"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "      <th>message_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>go until jurong point crazy available only in ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>u dun say so early hor u c already then say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "      <td>will ì_ b going to esplanade fr home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>pity  was in mood for that soany other suggest...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>the guy did some bitching but i acted like id ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>rofl its true to its name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label                                        sms_message  \\\n",
              "0      ham  Go until jurong point, crazy.. Available only ...   \n",
              "1      ham                      Ok lar... Joking wif u oni...   \n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3      ham  U dun say so early hor... U c already then say...   \n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
              "...    ...                                                ...   \n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
              "5568   ham              Will Ì_ b going to esplanade fr home?   \n",
              "5569   ham  Pity, * was in mood for that. So...any other s...   \n",
              "5570   ham  The guy did some bitching but I acted like i'd...   \n",
              "5571   ham                         Rofl. Its true to its name   \n",
              "\n",
              "                                          message_clean  \n",
              "0     go until jurong point crazy available only in ...  \n",
              "1                               ok lar joking wif u oni  \n",
              "2     free entry in 2 a wkly comp to win fa cup fina...  \n",
              "3           u dun say so early hor u c already then say  \n",
              "4     nah i dont think he goes to usf he lives aroun...  \n",
              "...                                                 ...  \n",
              "5567  this is the 2nd time we have tried 2 contact u...  \n",
              "5568               will ì_ b going to esplanade fr home  \n",
              "5569  pity  was in mood for that soany other suggest...  \n",
              "5570  the guy did some bitching but i acted like id ...  \n",
              "5571                          rofl its true to its name  \n",
              "\n",
              "[5572 rows x 3 columns]"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def limpiar_texto(text):\n",
        "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
        "    return text\n",
        "\n",
        "data['message_clean'] = data['sms_message'].apply(limpiar_texto)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "yJ3TkRDtxLPJ",
        "outputId": "11bf1907-4426-4cb3-a460-24bd497b93ed"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "      <th>message_clean</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>go until jurong point crazy available only in ...</td>\n",
              "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>u dun say so early hor u c already then say</td>\n",
              "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
              "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>[this, is, the, 2nd, time, we, have, tried, 2,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "      <td>will ì_ b going to esplanade fr home</td>\n",
              "      <td>[will, ì_, b, going, to, esplanade, fr, home]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>pity  was in mood for that soany other suggest...</td>\n",
              "      <td>[pity, was, in, mood, for, that, soany, other,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>the guy did some bitching but i acted like id ...</td>\n",
              "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>rofl its true to its name</td>\n",
              "      <td>[rofl, its, true, to, its, name]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label                                        sms_message  \\\n",
              "0      ham  Go until jurong point, crazy.. Available only ...   \n",
              "1      ham                      Ok lar... Joking wif u oni...   \n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3      ham  U dun say so early hor... U c already then say...   \n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
              "...    ...                                                ...   \n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
              "5568   ham              Will Ì_ b going to esplanade fr home?   \n",
              "5569   ham  Pity, * was in mood for that. So...any other s...   \n",
              "5570   ham  The guy did some bitching but I acted like i'd...   \n",
              "5571   ham                         Rofl. Its true to its name   \n",
              "\n",
              "                                          message_clean  \\\n",
              "0     go until jurong point crazy available only in ...   \n",
              "1                               ok lar joking wif u oni   \n",
              "2     free entry in 2 a wkly comp to win fa cup fina...   \n",
              "3           u dun say so early hor u c already then say   \n",
              "4     nah i dont think he goes to usf he lives aroun...   \n",
              "...                                                 ...   \n",
              "5567  this is the 2nd time we have tried 2 contact u...   \n",
              "5568               will ì_ b going to esplanade fr home   \n",
              "5569  pity  was in mood for that soany other suggest...   \n",
              "5570  the guy did some bitching but i acted like id ...   \n",
              "5571                          rofl its true to its name   \n",
              "\n",
              "                                                 tokens  \n",
              "0     [go, until, jurong, point, crazy, available, o...  \n",
              "1                        [ok, lar, joking, wif, u, oni]  \n",
              "2     [free, entry, in, 2, a, wkly, comp, to, win, f...  \n",
              "3     [u, dun, say, so, early, hor, u, c, already, t...  \n",
              "4     [nah, i, dont, think, he, goes, to, usf, he, l...  \n",
              "...                                                 ...  \n",
              "5567  [this, is, the, 2nd, time, we, have, tried, 2,...  \n",
              "5568      [will, ì_, b, going, to, esplanade, fr, home]  \n",
              "5569  [pity, was, in, mood, for, that, soany, other,...  \n",
              "5570  [the, guy, did, some, bitching, but, i, acted,...  \n",
              "5571                   [rofl, its, true, to, its, name]  \n",
              "\n",
              "[5572 rows x 4 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Tokenización\n",
        "data['tokens'] = data['message_clean'].apply(word_tokenize)\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "rssrvl5zxQMM",
        "outputId": "00a8cca4-e2a4-482d-86e2-5f6abd7d7d0d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "      <th>message_clean</th>\n",
              "      <th>tokens</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>go until jurong point crazy available only in ...</td>\n",
              "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>u dun say so early hor u c already then say</td>\n",
              "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
              "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>[2nd, time, tried, 2, contact, u, u, å750, pou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "      <td>will ì_ b going to esplanade fr home</td>\n",
              "      <td>[ì_, b, going, esplanade, fr, home]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>pity  was in mood for that soany other suggest...</td>\n",
              "      <td>[pity, mood, soany, suggestions]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>the guy did some bitching but i acted like id ...</td>\n",
              "      <td>[guy, bitching, acted, like, id, interested, b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>rofl its true to its name</td>\n",
              "      <td>[rofl, true, name]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label                                        sms_message  \\\n",
              "0      ham  Go until jurong point, crazy.. Available only ...   \n",
              "1      ham                      Ok lar... Joking wif u oni...   \n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3      ham  U dun say so early hor... U c already then say...   \n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
              "...    ...                                                ...   \n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
              "5568   ham              Will Ì_ b going to esplanade fr home?   \n",
              "5569   ham  Pity, * was in mood for that. So...any other s...   \n",
              "5570   ham  The guy did some bitching but I acted like i'd...   \n",
              "5571   ham                         Rofl. Its true to its name   \n",
              "\n",
              "                                          message_clean  \\\n",
              "0     go until jurong point crazy available only in ...   \n",
              "1                               ok lar joking wif u oni   \n",
              "2     free entry in 2 a wkly comp to win fa cup fina...   \n",
              "3           u dun say so early hor u c already then say   \n",
              "4     nah i dont think he goes to usf he lives aroun...   \n",
              "...                                                 ...   \n",
              "5567  this is the 2nd time we have tried 2 contact u...   \n",
              "5568               will ì_ b going to esplanade fr home   \n",
              "5569  pity  was in mood for that soany other suggest...   \n",
              "5570  the guy did some bitching but i acted like id ...   \n",
              "5571                          rofl its true to its name   \n",
              "\n",
              "                                                 tokens  \n",
              "0     [go, jurong, point, crazy, available, bugis, n...  \n",
              "1                        [ok, lar, joking, wif, u, oni]  \n",
              "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
              "3         [u, dun, say, early, hor, u, c, already, say]  \n",
              "4     [nah, dont, think, goes, usf, lives, around, t...  \n",
              "...                                                 ...  \n",
              "5567  [2nd, time, tried, 2, contact, u, u, å750, pou...  \n",
              "5568                [ì_, b, going, esplanade, fr, home]  \n",
              "5569                   [pity, mood, soany, suggestions]  \n",
              "5570  [guy, bitching, acted, like, id, interested, b...  \n",
              "5571                                 [rofl, true, name]  \n",
              "\n",
              "[5572 rows x 4 columns]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Eliminar stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "data['tokens'] = data['tokens'].apply(lambda x: [palabra for palabra in x if palabra not in stop_words])\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LhinbrG7xwAr",
        "outputId": "19abcbed-87ba-4317-a51c-1b01888a8486"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /home/usuario/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7BAURmPUxi7O",
        "outputId": "34699593-be2f-460a-9d66-3409f23b5fa5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "      <th>message_clean</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tokens_lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>go until jurong point crazy available only in ...</td>\n",
              "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
              "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>u dun say so early hor u c already then say</td>\n",
              "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
              "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
              "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
              "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>[2nd, time, tried, 2, contact, u, u, å750, pou...</td>\n",
              "      <td>[2nd, time, tried, 2, contact, u, u, å750, pou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "      <td>will ì_ b going to esplanade fr home</td>\n",
              "      <td>[ì_, b, going, esplanade, fr, home]</td>\n",
              "      <td>[ì_, b, going, esplanade, fr, home]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>pity  was in mood for that soany other suggest...</td>\n",
              "      <td>[pity, mood, soany, suggestions]</td>\n",
              "      <td>[pity, mood, soany, suggestion]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>the guy did some bitching but i acted like id ...</td>\n",
              "      <td>[guy, bitching, acted, like, id, interested, b...</td>\n",
              "      <td>[guy, bitching, acted, like, id, interested, b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>rofl its true to its name</td>\n",
              "      <td>[rofl, true, name]</td>\n",
              "      <td>[rofl, true, name]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label                                        sms_message  \\\n",
              "0      ham  Go until jurong point, crazy.. Available only ...   \n",
              "1      ham                      Ok lar... Joking wif u oni...   \n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3      ham  U dun say so early hor... U c already then say...   \n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
              "...    ...                                                ...   \n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
              "5568   ham              Will Ì_ b going to esplanade fr home?   \n",
              "5569   ham  Pity, * was in mood for that. So...any other s...   \n",
              "5570   ham  The guy did some bitching but I acted like i'd...   \n",
              "5571   ham                         Rofl. Its true to its name   \n",
              "\n",
              "                                          message_clean  \\\n",
              "0     go until jurong point crazy available only in ...   \n",
              "1                               ok lar joking wif u oni   \n",
              "2     free entry in 2 a wkly comp to win fa cup fina...   \n",
              "3           u dun say so early hor u c already then say   \n",
              "4     nah i dont think he goes to usf he lives aroun...   \n",
              "...                                                 ...   \n",
              "5567  this is the 2nd time we have tried 2 contact u...   \n",
              "5568               will ì_ b going to esplanade fr home   \n",
              "5569  pity  was in mood for that soany other suggest...   \n",
              "5570  the guy did some bitching but i acted like id ...   \n",
              "5571                          rofl its true to its name   \n",
              "\n",
              "                                                 tokens  \\\n",
              "0     [go, jurong, point, crazy, available, bugis, n...   \n",
              "1                        [ok, lar, joking, wif, u, oni]   \n",
              "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
              "3         [u, dun, say, early, hor, u, c, already, say]   \n",
              "4     [nah, dont, think, goes, usf, lives, around, t...   \n",
              "...                                                 ...   \n",
              "5567  [2nd, time, tried, 2, contact, u, u, å750, pou...   \n",
              "5568                [ì_, b, going, esplanade, fr, home]   \n",
              "5569                   [pity, mood, soany, suggestions]   \n",
              "5570  [guy, bitching, acted, like, id, interested, b...   \n",
              "5571                                 [rofl, true, name]   \n",
              "\n",
              "                                      tokens_lemmatized  \n",
              "0     [go, jurong, point, crazy, available, bugis, n...  \n",
              "1                        [ok, lar, joking, wif, u, oni]  \n",
              "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
              "3         [u, dun, say, early, hor, u, c, already, say]  \n",
              "4     [nah, dont, think, go, usf, life, around, though]  \n",
              "...                                                 ...  \n",
              "5567  [2nd, time, tried, 2, contact, u, u, å750, pou...  \n",
              "5568                [ì_, b, going, esplanade, fr, home]  \n",
              "5569                    [pity, mood, soany, suggestion]  \n",
              "5570  [guy, bitching, acted, like, id, interested, b...  \n",
              "5571                                 [rofl, true, name]  \n",
              "\n",
              "[5572 rows x 5 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Lematización\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "data['tokens_lemmatized'] = data['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "RK5sfBqyx58m",
        "outputId": "5e934268-8691-4593-d132-cf6f7e6f99b2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "      <th>message_clean</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tokens_lemmatized</th>\n",
              "      <th>processed_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>go until jurong point crazy available only in ...</td>\n",
              "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
              "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
              "      <td>go jurong point crazy available bugis n great ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
              "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>u dun say so early hor u c already then say</td>\n",
              "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
              "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
              "      <td>u dun say early hor u c already say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
              "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
              "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
              "      <td>nah dont think go usf life around though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>[2nd, time, tried, 2, contact, u, u, å750, pou...</td>\n",
              "      <td>[2nd, time, tried, 2, contact, u, u, å750, pou...</td>\n",
              "      <td>2nd time tried 2 contact u u å750 pound prize ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "      <td>will ì_ b going to esplanade fr home</td>\n",
              "      <td>[ì_, b, going, esplanade, fr, home]</td>\n",
              "      <td>[ì_, b, going, esplanade, fr, home]</td>\n",
              "      <td>ì_ b going esplanade fr home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>pity  was in mood for that soany other suggest...</td>\n",
              "      <td>[pity, mood, soany, suggestions]</td>\n",
              "      <td>[pity, mood, soany, suggestion]</td>\n",
              "      <td>pity mood soany suggestion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>the guy did some bitching but i acted like id ...</td>\n",
              "      <td>[guy, bitching, acted, like, id, interested, b...</td>\n",
              "      <td>[guy, bitching, acted, like, id, interested, b...</td>\n",
              "      <td>guy bitching acted like id interested buying s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>rofl its true to its name</td>\n",
              "      <td>[rofl, true, name]</td>\n",
              "      <td>[rofl, true, name]</td>\n",
              "      <td>rofl true name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label                                        sms_message  \\\n",
              "0      ham  Go until jurong point, crazy.. Available only ...   \n",
              "1      ham                      Ok lar... Joking wif u oni...   \n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3      ham  U dun say so early hor... U c already then say...   \n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
              "...    ...                                                ...   \n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
              "5568   ham              Will Ì_ b going to esplanade fr home?   \n",
              "5569   ham  Pity, * was in mood for that. So...any other s...   \n",
              "5570   ham  The guy did some bitching but I acted like i'd...   \n",
              "5571   ham                         Rofl. Its true to its name   \n",
              "\n",
              "                                          message_clean  \\\n",
              "0     go until jurong point crazy available only in ...   \n",
              "1                               ok lar joking wif u oni   \n",
              "2     free entry in 2 a wkly comp to win fa cup fina...   \n",
              "3           u dun say so early hor u c already then say   \n",
              "4     nah i dont think he goes to usf he lives aroun...   \n",
              "...                                                 ...   \n",
              "5567  this is the 2nd time we have tried 2 contact u...   \n",
              "5568               will ì_ b going to esplanade fr home   \n",
              "5569  pity  was in mood for that soany other suggest...   \n",
              "5570  the guy did some bitching but i acted like id ...   \n",
              "5571                          rofl its true to its name   \n",
              "\n",
              "                                                 tokens  \\\n",
              "0     [go, jurong, point, crazy, available, bugis, n...   \n",
              "1                        [ok, lar, joking, wif, u, oni]   \n",
              "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
              "3         [u, dun, say, early, hor, u, c, already, say]   \n",
              "4     [nah, dont, think, goes, usf, lives, around, t...   \n",
              "...                                                 ...   \n",
              "5567  [2nd, time, tried, 2, contact, u, u, å750, pou...   \n",
              "5568                [ì_, b, going, esplanade, fr, home]   \n",
              "5569                   [pity, mood, soany, suggestions]   \n",
              "5570  [guy, bitching, acted, like, id, interested, b...   \n",
              "5571                                 [rofl, true, name]   \n",
              "\n",
              "                                      tokens_lemmatized  \\\n",
              "0     [go, jurong, point, crazy, available, bugis, n...   \n",
              "1                        [ok, lar, joking, wif, u, oni]   \n",
              "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
              "3         [u, dun, say, early, hor, u, c, already, say]   \n",
              "4     [nah, dont, think, go, usf, life, around, though]   \n",
              "...                                                 ...   \n",
              "5567  [2nd, time, tried, 2, contact, u, u, å750, pou...   \n",
              "5568                [ì_, b, going, esplanade, fr, home]   \n",
              "5569                    [pity, mood, soany, suggestion]   \n",
              "5570  [guy, bitching, acted, like, id, interested, b...   \n",
              "5571                                 [rofl, true, name]   \n",
              "\n",
              "                                      processed_message  \n",
              "0     go jurong point crazy available bugis n great ...  \n",
              "1                               ok lar joking wif u oni  \n",
              "2     free entry 2 wkly comp win fa cup final tkts 2...  \n",
              "3                   u dun say early hor u c already say  \n",
              "4              nah dont think go usf life around though  \n",
              "...                                                 ...  \n",
              "5567  2nd time tried 2 contact u u å750 pound prize ...  \n",
              "5568                       ì_ b going esplanade fr home  \n",
              "5569                         pity mood soany suggestion  \n",
              "5570  guy bitching acted like id interested buying s...  \n",
              "5571                                     rofl true name  \n",
              "\n",
              "[5572 rows x 6 columns]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Unir tokens lematizados en una única cadena de texto\n",
        "data['processed_message'] = data['tokens_lemmatized'].apply(lambda x: ' '.join(x))\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "aS-tjJ-Nwpf8",
        "outputId": "144469f9-1aad-4d82-d8d3-35cda00287d2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "      <th>message_clean</th>\n",
              "      <th>tokens</th>\n",
              "      <th>tokens_lemmatized</th>\n",
              "      <th>processed_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "      <td>go until jurong point crazy available only in ...</td>\n",
              "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
              "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
              "      <td>go jurong point crazy available bugis n great ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
              "      <td>ok lar joking wif u oni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
              "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
              "      <td>free entry 2 wkly comp win fa cup final tkts 2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "      <td>u dun say so early hor u c already then say</td>\n",
              "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
              "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
              "      <td>u dun say early hor u c already say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
              "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
              "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
              "      <td>nah dont think go usf life around though</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5567</th>\n",
              "      <td>spam</td>\n",
              "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>this is the 2nd time we have tried 2 contact u...</td>\n",
              "      <td>[2nd, time, tried, 2, contact, u, u, å750, pou...</td>\n",
              "      <td>[2nd, time, tried, 2, contact, u, u, å750, pou...</td>\n",
              "      <td>2nd time tried 2 contact u u å750 pound prize ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5568</th>\n",
              "      <td>ham</td>\n",
              "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
              "      <td>will ì_ b going to esplanade fr home</td>\n",
              "      <td>[ì_, b, going, esplanade, fr, home]</td>\n",
              "      <td>[ì_, b, going, esplanade, fr, home]</td>\n",
              "      <td>ì_ b going esplanade fr home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5569</th>\n",
              "      <td>ham</td>\n",
              "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
              "      <td>pity  was in mood for that soany other suggest...</td>\n",
              "      <td>[pity, mood, soany, suggestions]</td>\n",
              "      <td>[pity, mood, soany, suggestion]</td>\n",
              "      <td>pity mood soany suggestion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5570</th>\n",
              "      <td>ham</td>\n",
              "      <td>The guy did some bitching but I acted like i'd...</td>\n",
              "      <td>the guy did some bitching but i acted like id ...</td>\n",
              "      <td>[guy, bitching, acted, like, id, interested, b...</td>\n",
              "      <td>[guy, bitching, acted, like, id, interested, b...</td>\n",
              "      <td>guy bitching acted like id interested buying s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5571</th>\n",
              "      <td>ham</td>\n",
              "      <td>Rofl. Its true to its name</td>\n",
              "      <td>rofl its true to its name</td>\n",
              "      <td>[rofl, true, name]</td>\n",
              "      <td>[rofl, true, name]</td>\n",
              "      <td>rofl true name</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5572 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     label                                        sms_message  \\\n",
              "0      ham  Go until jurong point, crazy.. Available only ...   \n",
              "1      ham                      Ok lar... Joking wif u oni...   \n",
              "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
              "3      ham  U dun say so early hor... U c already then say...   \n",
              "4      ham  Nah I don't think he goes to usf, he lives aro...   \n",
              "...    ...                                                ...   \n",
              "5567  spam  This is the 2nd time we have tried 2 contact u...   \n",
              "5568   ham              Will Ì_ b going to esplanade fr home?   \n",
              "5569   ham  Pity, * was in mood for that. So...any other s...   \n",
              "5570   ham  The guy did some bitching but I acted like i'd...   \n",
              "5571   ham                         Rofl. Its true to its name   \n",
              "\n",
              "                                          message_clean  \\\n",
              "0     go until jurong point crazy available only in ...   \n",
              "1                               ok lar joking wif u oni   \n",
              "2     free entry in 2 a wkly comp to win fa cup fina...   \n",
              "3           u dun say so early hor u c already then say   \n",
              "4     nah i dont think he goes to usf he lives aroun...   \n",
              "...                                                 ...   \n",
              "5567  this is the 2nd time we have tried 2 contact u...   \n",
              "5568               will ì_ b going to esplanade fr home   \n",
              "5569  pity  was in mood for that soany other suggest...   \n",
              "5570  the guy did some bitching but i acted like id ...   \n",
              "5571                          rofl its true to its name   \n",
              "\n",
              "                                                 tokens  \\\n",
              "0     [go, jurong, point, crazy, available, bugis, n...   \n",
              "1                        [ok, lar, joking, wif, u, oni]   \n",
              "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
              "3         [u, dun, say, early, hor, u, c, already, say]   \n",
              "4     [nah, dont, think, goes, usf, lives, around, t...   \n",
              "...                                                 ...   \n",
              "5567  [2nd, time, tried, 2, contact, u, u, å750, pou...   \n",
              "5568                [ì_, b, going, esplanade, fr, home]   \n",
              "5569                   [pity, mood, soany, suggestions]   \n",
              "5570  [guy, bitching, acted, like, id, interested, b...   \n",
              "5571                                 [rofl, true, name]   \n",
              "\n",
              "                                      tokens_lemmatized  \\\n",
              "0     [go, jurong, point, crazy, available, bugis, n...   \n",
              "1                        [ok, lar, joking, wif, u, oni]   \n",
              "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
              "3         [u, dun, say, early, hor, u, c, already, say]   \n",
              "4     [nah, dont, think, go, usf, life, around, though]   \n",
              "...                                                 ...   \n",
              "5567  [2nd, time, tried, 2, contact, u, u, å750, pou...   \n",
              "5568                [ì_, b, going, esplanade, fr, home]   \n",
              "5569                    [pity, mood, soany, suggestion]   \n",
              "5570  [guy, bitching, acted, like, id, interested, b...   \n",
              "5571                                 [rofl, true, name]   \n",
              "\n",
              "                                      processed_message  \n",
              "0     go jurong point crazy available bugis n great ...  \n",
              "1                               ok lar joking wif u oni  \n",
              "2     free entry 2 wkly comp win fa cup final tkts 2...  \n",
              "3                   u dun say early hor u c already say  \n",
              "4              nah dont think go usf life around though  \n",
              "...                                                 ...  \n",
              "5567  2nd time tried 2 contact u u å750 pound prize ...  \n",
              "5568                       ì_ b going esplanade fr home  \n",
              "5569                         pity mood soany suggestion  \n",
              "5570  guy bitching acted like id interested buying s...  \n",
              "5571                                     rofl true name  \n",
              "\n",
              "[5572 rows x 6 columns]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Verificar los datos procesados\n",
        "#print(data[['label', 'processed_message']])\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Modelo de clasificacion de spam"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "#bolsa de palabras\n",
        "vectorizador = CountVectorizer()\n",
        "\n",
        "#aplicar el vectorizador a nuestro dataset\n",
        "X = vectorizador.fit_transform(data['processed_message'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.99      0.98      0.98       965\n",
            "        spam       0.90      0.91      0.90       150\n",
            "\n",
            "    accuracy                           0.97      1115\n",
            "   macro avg       0.94      0.95      0.94      1115\n",
            "weighted avg       0.97      0.97      0.97      1115\n",
            "\n",
            "Accuracy: 0.9739910313901345\n"
          ]
        }
      ],
      "source": [
        "#Dividir los datos en conjuntos de entrenamiento y prueba\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, data['label'], test_size=0.2, random_state=42)\n",
        "\n",
        "#crear y entrenar el modelo\n",
        "modelo = MultinomialNB()\n",
        "modelo.fit(x_train, y_train)\n",
        "\n",
        "#predecir los resultados\n",
        "y_pred = modelo.predict(x_test)\n",
        "\n",
        "#evaluar el modelo\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cross-validation scores:  [0.97488789 0.97757848 0.97486535 0.97307002 0.97127469]\n"
          ]
        }
      ],
      "source": [
        "#cross-validation\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "cv_mnb = cross_val_score(MultinomialNB(), X, data['label'], cv=5)\n",
        "print(\"Cross-validation scores: \", cv_mnb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "#TF-IDF\n",
        "vectorizador2 = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizador2.fit_transform(data['processed_message'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_entrenamiento, x_prueba, y_entrenamiento, y_prueba = train_test_split(X, data['label'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;MultinomialNB<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "modelo2 = MultinomialNB()\n",
        "modelo2.fit(x_entrenamiento, y_entrenamiento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_prediccion = modelo2.predict(x_prueba)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.96      1.00      0.98       965\n",
            "        spam       1.00      0.73      0.84       150\n",
            "\n",
            "    accuracy                           0.96      1115\n",
            "   macro avg       0.98      0.86      0.91      1115\n",
            "weighted avg       0.96      0.96      0.96      1115\n",
            "\n",
            "accuracy_score:  0.9632286995515695\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_prueba, y_prediccion))\n",
        "print(\"accuracy_score: \", accuracy_score(y_prueba, y_prediccion))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Regresion logistica\n",
        "vectorizador3 = CountVectorizer(stop_words='english', max_features=1000)\n",
        "\n",
        "x = vectorizador3.fit_transform(data['processed_message'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train3, x_test3, y_train3, y_test3 = train_test_split(x, data['label'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: black;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-2 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-2 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-2 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: block;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-2 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-2 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-2 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-2 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 1ex;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-2 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression()</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression(random_state=16)\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "modelo3 = LogisticRegression()\n",
        "modelo3.fit(x_train3, y_train3)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9757847533632287"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_pred3 = modelo3.predict(x_test3)\n",
        "accuracy_score(y_test3, y_pred3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         ham       0.97      1.00      0.99       965\n",
            "        spam       0.99      0.83      0.90       150\n",
            "\n",
            "    accuracy                           0.98      1115\n",
            "   macro avg       0.98      0.91      0.94      1115\n",
            "weighted avg       0.98      0.98      0.97      1115\n",
            "\n",
            "accuracy_score:  0.9757847533632287\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test3, y_pred3))\n",
        "print(\"accuracy_score: \", accuracy_score(y_test3, y_pred3))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análisis de sentimientos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.pipeline import Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "datos = pd.read_csv('/home/usuario/Proyectos/talentoTech/data_nlp.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AU2LNDRGFOS8J</td>\n",
              "      <td>7310172101</td>\n",
              "      <td>Dog Treat</td>\n",
              "      <td>very good</td>\n",
              "      <td>This product is a very health snack for your p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A3RRSB7FFM07ZU</td>\n",
              "      <td>7310172101</td>\n",
              "      <td>Dog Treat</td>\n",
              "      <td>Dogs Love These!</td>\n",
              "      <td>My girls love these. I cut them up smaller and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AFH6TT0SWN59L</td>\n",
              "      <td>7310172101</td>\n",
              "      <td>Dog Treat</td>\n",
              "      <td>Fast shipment</td>\n",
              "      <td>This is 2.5 oz larger than what you can find i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ALAA0P3GK1VBR</td>\n",
              "      <td>7310172101</td>\n",
              "      <td>Dog Treat</td>\n",
              "      <td>Dogs Love It</td>\n",
              "      <td>I have one dog that is a picky eater. I crumbl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A3EKHSRZKXRIFK</td>\n",
              "      <td>7310172101</td>\n",
              "      <td>Dog Treat</td>\n",
              "      <td>Golden loves them!</td>\n",
              "      <td>My Golden can get picky and eating is not a pr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1077</th>\n",
              "      <td>A3T0OTH5072YRE</td>\n",
              "      <td>B004Z33GI6</td>\n",
              "      <td>Lemonade</td>\n",
              "      <td>Honest Ade Classic Lemonade</td>\n",
              "      <td>This was pretty bad.  Not completely terrible,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1078</th>\n",
              "      <td>A1UUPKHLG9MR9L</td>\n",
              "      <td>B004Z33GI6</td>\n",
              "      <td>Lemonade</td>\n",
              "      <td>Awful.</td>\n",
              "      <td>This stuff is terrible.  There must be a huge ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1079</th>\n",
              "      <td>A1N65D9MJX89GI</td>\n",
              "      <td>B004Z33GI6</td>\n",
              "      <td>Lemonade</td>\n",
              "      <td>AMAZING AND ADDICTING!</td>\n",
              "      <td>This is the best and most delicious 0-cal drin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1080</th>\n",
              "      <td>AELQNIEEB4Y40</td>\n",
              "      <td>B004Z33GI6</td>\n",
              "      <td>Lemonade</td>\n",
              "      <td>Beware..your results may vary</td>\n",
              "      <td>This product is very hit or miss for people. I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1081</th>\n",
              "      <td>A2I6DISKM0YKM8</td>\n",
              "      <td>B004Z33GI6</td>\n",
              "      <td>Lemonade</td>\n",
              "      <td>Soooo good!</td>\n",
              "      <td>With summer upon us (it was almost 100 degrees...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1082 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              UserId   ProductId Product Name                        Summary  \\\n",
              "0      AU2LNDRGFOS8J  7310172101    Dog Treat                      very good   \n",
              "1     A3RRSB7FFM07ZU  7310172101    Dog Treat               Dogs Love These!   \n",
              "2      AFH6TT0SWN59L  7310172101    Dog Treat                  Fast shipment   \n",
              "3      ALAA0P3GK1VBR  7310172101    Dog Treat                   Dogs Love It   \n",
              "4     A3EKHSRZKXRIFK  7310172101    Dog Treat             Golden loves them!   \n",
              "...              ...         ...          ...                            ...   \n",
              "1077  A3T0OTH5072YRE  B004Z33GI6     Lemonade    Honest Ade Classic Lemonade   \n",
              "1078  A1UUPKHLG9MR9L  B004Z33GI6     Lemonade                         Awful.   \n",
              "1079  A1N65D9MJX89GI  B004Z33GI6     Lemonade         AMAZING AND ADDICTING!   \n",
              "1080   AELQNIEEB4Y40  B004Z33GI6     Lemonade  Beware..your results may vary   \n",
              "1081  A2I6DISKM0YKM8  B004Z33GI6     Lemonade                    Soooo good!   \n",
              "\n",
              "                                                   Text  \n",
              "0     This product is a very health snack for your p...  \n",
              "1     My girls love these. I cut them up smaller and...  \n",
              "2     This is 2.5 oz larger than what you can find i...  \n",
              "3     I have one dog that is a picky eater. I crumbl...  \n",
              "4     My Golden can get picky and eating is not a pr...  \n",
              "...                                                 ...  \n",
              "1077  This was pretty bad.  Not completely terrible,...  \n",
              "1078  This stuff is terrible.  There must be a huge ...  \n",
              "1079  This is the best and most delicious 0-cal drin...  \n",
              "1080  This product is very hit or miss for people. I...  \n",
              "1081  With summer upon us (it was almost 100 degrees...  \n",
              "\n",
              "[1082 rows x 5 columns]"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "def agregar_columna_sentimientos(texto):\n",
        "    palabras_positivas = ['good', 'great', 'love', 'best', 'wonderful', 'delightful', 'excellent']\n",
        "    palabras_negativas = ['bad', 'worst', 'terrible', 'awful', 'disappointing', 'poor', 'hate']\n",
        "    \n",
        "    texto.lower()\n",
        "    puntaje_positivo = sum(palabra in texto for palabra in palabras_positivas)\n",
        "    puntaje_negativo = sum(palabra in texto for palabra in palabras_negativas)\n",
        "    \n",
        "    return 1 if puntaje_positivo > puntaje_negativo else 0 if puntaje_negativo > 0 else -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>sentimiento</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AU2LNDRGFOS8J</td>\n",
              "      <td>7310172101</td>\n",
              "      <td>Dog Treat</td>\n",
              "      <td>very good</td>\n",
              "      <td>This product is a very health snack for your p...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A3RRSB7FFM07ZU</td>\n",
              "      <td>7310172101</td>\n",
              "      <td>Dog Treat</td>\n",
              "      <td>Dogs Love These!</td>\n",
              "      <td>My girls love these. I cut them up smaller and...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>AFH6TT0SWN59L</td>\n",
              "      <td>7310172101</td>\n",
              "      <td>Dog Treat</td>\n",
              "      <td>Fast shipment</td>\n",
              "      <td>This is 2.5 oz larger than what you can find i...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ALAA0P3GK1VBR</td>\n",
              "      <td>7310172101</td>\n",
              "      <td>Dog Treat</td>\n",
              "      <td>Dogs Love It</td>\n",
              "      <td>I have one dog that is a picky eater. I crumbl...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A3EKHSRZKXRIFK</td>\n",
              "      <td>7310172101</td>\n",
              "      <td>Dog Treat</td>\n",
              "      <td>Golden loves them!</td>\n",
              "      <td>My Golden can get picky and eating is not a pr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1077</th>\n",
              "      <td>A3T0OTH5072YRE</td>\n",
              "      <td>B004Z33GI6</td>\n",
              "      <td>Lemonade</td>\n",
              "      <td>Honest Ade Classic Lemonade</td>\n",
              "      <td>This was pretty bad.  Not completely terrible,...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1078</th>\n",
              "      <td>A1UUPKHLG9MR9L</td>\n",
              "      <td>B004Z33GI6</td>\n",
              "      <td>Lemonade</td>\n",
              "      <td>Awful.</td>\n",
              "      <td>This stuff is terrible.  There must be a huge ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1079</th>\n",
              "      <td>A1N65D9MJX89GI</td>\n",
              "      <td>B004Z33GI6</td>\n",
              "      <td>Lemonade</td>\n",
              "      <td>AMAZING AND ADDICTING!</td>\n",
              "      <td>This is the best and most delicious 0-cal drin...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1080</th>\n",
              "      <td>AELQNIEEB4Y40</td>\n",
              "      <td>B004Z33GI6</td>\n",
              "      <td>Lemonade</td>\n",
              "      <td>Beware..your results may vary</td>\n",
              "      <td>This product is very hit or miss for people. I...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1081</th>\n",
              "      <td>A2I6DISKM0YKM8</td>\n",
              "      <td>B004Z33GI6</td>\n",
              "      <td>Lemonade</td>\n",
              "      <td>Soooo good!</td>\n",
              "      <td>With summer upon us (it was almost 100 degrees...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1082 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              UserId   ProductId Product Name                        Summary  \\\n",
              "0      AU2LNDRGFOS8J  7310172101    Dog Treat                      very good   \n",
              "1     A3RRSB7FFM07ZU  7310172101    Dog Treat               Dogs Love These!   \n",
              "2      AFH6TT0SWN59L  7310172101    Dog Treat                  Fast shipment   \n",
              "3      ALAA0P3GK1VBR  7310172101    Dog Treat                   Dogs Love It   \n",
              "4     A3EKHSRZKXRIFK  7310172101    Dog Treat             Golden loves them!   \n",
              "...              ...         ...          ...                            ...   \n",
              "1077  A3T0OTH5072YRE  B004Z33GI6     Lemonade    Honest Ade Classic Lemonade   \n",
              "1078  A1UUPKHLG9MR9L  B004Z33GI6     Lemonade                         Awful.   \n",
              "1079  A1N65D9MJX89GI  B004Z33GI6     Lemonade         AMAZING AND ADDICTING!   \n",
              "1080   AELQNIEEB4Y40  B004Z33GI6     Lemonade  Beware..your results may vary   \n",
              "1081  A2I6DISKM0YKM8  B004Z33GI6     Lemonade                    Soooo good!   \n",
              "\n",
              "                                                   Text  sentimiento  \n",
              "0     This product is a very health snack for your p...           -1  \n",
              "1     My girls love these. I cut them up smaller and...            1  \n",
              "2     This is 2.5 oz larger than what you can find i...           -1  \n",
              "3     I have one dog that is a picky eater. I crumbl...            1  \n",
              "4     My Golden can get picky and eating is not a pr...            1  \n",
              "...                                                 ...          ...  \n",
              "1077  This was pretty bad.  Not completely terrible,...            0  \n",
              "1078  This stuff is terrible.  There must be a huge ...            0  \n",
              "1079  This is the best and most delicious 0-cal drin...            1  \n",
              "1080  This product is very hit or miss for people. I...           -1  \n",
              "1081  With summer upon us (it was almost 100 degrees...            1  \n",
              "\n",
              "[1082 rows x 6 columns]"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datos['sentimiento'] = datos['Text'].apply(agregar_columna_sentimientos)\n",
        "datos "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "x_train4, x_test4, y_train4, y_test4 = train_test_split(datos['Text'], datos['sentimiento'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('vectorizador', CountVectorizer(stop_words='english')),\n",
        "    ('modelo_NB', MultinomialNB())\n",
        "])\n",
        "\n",
        "pipeline.fit(x_train4, y_train4)\n",
        "y_prediccion4 = pipeline.predict(x_test4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "accuracy_score4 = accuracy_score(y_test4, y_prediccion4)\n",
        "reporte_score4 = classification_report(y_test4, y_prediccion4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.6267281105990783               precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.62      0.24      0.35        75\n",
            "           0       0.53      0.70      0.60        27\n",
            "           1       0.65      0.86      0.74       115\n",
            "\n",
            "    accuracy                           0.63       217\n",
            "   macro avg       0.60      0.60      0.56       217\n",
            "weighted avg       0.63      0.63      0.59       217\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(accuracy_score4, reporte_score4)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['00' '000' '05' ... 'ziploc' 'zipper' 'zucchini']\n",
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "#Matriz de confucion\n",
        "vectorizador4 = CountVectorizer(stop_words='english')\n",
        "x4 = vectorizador4.fit_transform(datos['Text'])\n",
        "\n",
        "nombre_features = vectorizador4.get_feature_names_out()\n",
        "\n",
        "print(nombre_features)\n",
        "print(x4.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   00  000  05  0631  07036  0790700506  08  09  0z  10  ...  zenith  zero  \\\n",
            "0   0    0   0     0      0           0   0   0   0   0  ...       0     0   \n",
            "1   0    0   0     0      0           0   0   0   0   0  ...       0     0   \n",
            "2   0    0   0     0      0           0   0   0   0   0  ...       0     0   \n",
            "3   0    0   0     0      0           0   0   0   0   0  ...       0     0   \n",
            "4   0    0   0     0      0           0   0   0   0   0  ...       0     0   \n",
            "\n",
            "   zest  zig  zing  zinginess  zip  ziploc  zipper  zucchini  \n",
            "0     0    0     0          0    0       0       0         0  \n",
            "1     0    0     0          0    0       0       0         0  \n",
            "2     0    0     0          0    0       0       0         0  \n",
            "3     0    0     0          0    0       0       0         0  \n",
            "4     0    0     0          0    0       0       0         0  \n",
            "\n",
            "[5 rows x 6907 columns]\n"
          ]
        }
      ],
      "source": [
        "datos_completos = pd.DataFrame(x4.toarray(), columns=nombre_features )\n",
        "print(datos_completos.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "cm = confusion_matrix(y_test4, y_prediccion4)\n",
        "labels = ['negativo', 'neutral', 'positivo']\n",
        "cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
        "sns.heatmap(cm, annot=True, fmt='g', cmap='YlGnBu')\n",
        "plt.xlabel('predicciones')\n",
        "plt.ylabel('reales')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predecir_sentimiento(texto, pipeline_entrenado):\n",
        "    texto_procesado = texto.lower()\n",
        "    print(texto_procesado)\n",
        "    prediccion = pipeline_entrenado.predict([texto_procesado])\n",
        "    \n",
        "    \n",
        "    return prediccion[0] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'the model s '"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "texto = 'the model s '\n",
        "texto"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "the model s \n",
            "El sentimiento es positivo\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "sentimiento = predecir_sentimiento(texto, pipeline)\n",
        "if sentimiento == 1:\n",
        "    print(\"El sentimiento es positivo\")\n",
        "else:\n",
        "    if sentimiento == 0:\n",
        "        print(\"El sentimiento es negativo\")\n",
        "    else:\n",
        "        print('El sentimiento es neutro')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analisis de sentimiento usando Vader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /home/usuario/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nltk.download('vader_lexicon')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "#col_resumen = 'Sumary'\n",
        "#for i.resumen in enumerate(datos[col_resumen]):\n",
        "#    print('i:', i, 'Resumen:', i.resumen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from collections import defaultdict, Counter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejercicio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>urls</th>\n",
              "      <th>created_at</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1013558869728071685</td>\n",
              "      <td>RT @NASA_Johnson: This week on \"Houston, We Ha...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>Sun Jul 01 23:04:00 +0000 2018</td>\n",
              "      <td>0</td>\n",
              "      <td>96</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1013529203990581249</td>\n",
              "      <td>In this week's #STEMonStation, @astro_ricky de...</td>\n",
              "      <td>['STEMonStation']</td>\n",
              "      <td>['https://youtu.be/34bFgA3H3hQ']</td>\n",
              "      <td>Sun Jul 01 21:06:07 +0000 2018</td>\n",
              "      <td>1587</td>\n",
              "      <td>429</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1013498567309348864</td>\n",
              "      <td>Could these tiny, electricity-producing bacter...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['https://youtu.be/KhsCg7pmv0o']</td>\n",
              "      <td>Sun Jul 01 19:04:22 +0000 2018</td>\n",
              "      <td>1869</td>\n",
              "      <td>515</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1013486392134062080</td>\n",
              "      <td>RT @NASAInterns: Ready to be part of the futur...</td>\n",
              "      <td>['scientific']</td>\n",
              "      <td>[]</td>\n",
              "      <td>Sun Jul 01 18:16:00 +0000 2018</td>\n",
              "      <td>0</td>\n",
              "      <td>250</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1013477085279551488</td>\n",
              "      <td>Weâre inviting social media users to go behi...</td>\n",
              "      <td>['TwilightZone']</td>\n",
              "      <td>['https://go.nasa.gov/2KFd8Ka']</td>\n",
              "      <td>Sun Jul 01 17:39:01 +0000 2018</td>\n",
              "      <td>1167</td>\n",
              "      <td>262</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3240</th>\n",
              "      <td>918229105706971137</td>\n",
              "      <td>Finding billions of planets around other stars...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['http://go.nasa.gov/2xAmK3m']</td>\n",
              "      <td>Wed Oct 11 21:37:33 +0000 2017</td>\n",
              "      <td>2300</td>\n",
              "      <td>596</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3241</th>\n",
              "      <td>918198523610484737</td>\n",
              "      <td>Newly-adapted imaging procedures allow researc...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['http://go.nasa.gov/2kGGIDr']</td>\n",
              "      <td>Wed Oct 11 19:36:01 +0000 2017</td>\n",
              "      <td>1260</td>\n",
              "      <td>316</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3242</th>\n",
              "      <td>918177752473325568</td>\n",
              "      <td>RT @Space_Station: LIVE NOW: @Astro_Kanai, @As...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>Wed Oct 11 18:13:29 +0000 2017</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>Twitter Web Client</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3243</th>\n",
              "      <td>918162536134037514</td>\n",
              "      <td>Meet the next three humans launching to @Space...</td>\n",
              "      <td>['askNASA']</td>\n",
              "      <td>['http://www.nasa.gov/live']</td>\n",
              "      <td>Wed Oct 11 17:13:01 +0000 2017</td>\n",
              "      <td>2252</td>\n",
              "      <td>506</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3244</th>\n",
              "      <td>918137015924854786</td>\n",
              "      <td>.@NASAEarth satellites saw the northern Califo...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['http://go.nasa.gov/2kHTSQE']</td>\n",
              "      <td>Wed Oct 11 15:31:37 +0000 2017</td>\n",
              "      <td>1400</td>\n",
              "      <td>548</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3245 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       id                                          full_text  \\\n",
              "0     1013558869728071685  RT @NASA_Johnson: This week on \"Houston, We Ha...   \n",
              "1     1013529203990581249  In this week's #STEMonStation, @astro_ricky de...   \n",
              "2     1013498567309348864  Could these tiny, electricity-producing bacter...   \n",
              "3     1013486392134062080  RT @NASAInterns: Ready to be part of the futur...   \n",
              "4     1013477085279551488  Weâre inviting social media users to go behi...   \n",
              "...                   ...                                                ...   \n",
              "3240   918229105706971137  Finding billions of planets around other stars...   \n",
              "3241   918198523610484737  Newly-adapted imaging procedures allow researc...   \n",
              "3242   918177752473325568  RT @Space_Station: LIVE NOW: @Astro_Kanai, @As...   \n",
              "3243   918162536134037514  Meet the next three humans launching to @Space...   \n",
              "3244   918137015924854786  .@NASAEarth satellites saw the northern Califo...   \n",
              "\n",
              "               hashtags                              urls  \\\n",
              "0                    []                                []   \n",
              "1     ['STEMonStation']  ['https://youtu.be/34bFgA3H3hQ']   \n",
              "2                    []  ['https://youtu.be/KhsCg7pmv0o']   \n",
              "3        ['scientific']                                []   \n",
              "4      ['TwilightZone']   ['https://go.nasa.gov/2KFd8Ka']   \n",
              "...                 ...                               ...   \n",
              "3240                 []    ['http://go.nasa.gov/2xAmK3m']   \n",
              "3241                 []    ['http://go.nasa.gov/2kGGIDr']   \n",
              "3242                 []                                []   \n",
              "3243        ['askNASA']      ['http://www.nasa.gov/live']   \n",
              "3244                 []    ['http://go.nasa.gov/2kHTSQE']   \n",
              "\n",
              "                          created_at  favorite_count  retweet_count  \\\n",
              "0     Sun Jul 01 23:04:00 +0000 2018               0             96   \n",
              "1     Sun Jul 01 21:06:07 +0000 2018            1587            429   \n",
              "2     Sun Jul 01 19:04:22 +0000 2018            1869            515   \n",
              "3     Sun Jul 01 18:16:00 +0000 2018               0            250   \n",
              "4     Sun Jul 01 17:39:01 +0000 2018            1167            262   \n",
              "...                              ...             ...            ...   \n",
              "3240  Wed Oct 11 21:37:33 +0000 2017            2300            596   \n",
              "3241  Wed Oct 11 19:36:01 +0000 2017            1260            316   \n",
              "3242  Wed Oct 11 18:13:29 +0000 2017               0            140   \n",
              "3243  Wed Oct 11 17:13:01 +0000 2017            2252            506   \n",
              "3244  Wed Oct 11 15:31:37 +0000 2017            1400            548   \n",
              "\n",
              "                  source  \n",
              "0               Sprinklr  \n",
              "1               Sprinklr  \n",
              "2               Sprinklr  \n",
              "3               Sprinklr  \n",
              "4               Sprinklr  \n",
              "...                  ...  \n",
              "3240            Sprinklr  \n",
              "3241            Sprinklr  \n",
              "3242  Twitter Web Client  \n",
              "3243            Sprinklr  \n",
              "3244            Sprinklr  \n",
              "\n",
              "[3245 rows x 8 columns]"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df5 = pd.read_csv('https://raw.githubusercontent.com/eleanorstrib/twitter_timeline_analysis_1/refs/heads/master/NASA_tweets.csv', encoding='latin-1')\n",
        "df5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(3245, 8)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df5.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0       RT @NASA_Johnson: This week on \"Houston, We Ha...\n",
              "1       In this week's #STEMonStation, @astro_ricky de...\n",
              "2       Could these tiny, electricity-producing bacter...\n",
              "3       RT @NASAInterns: Ready to be part of the futur...\n",
              "4       Weâre inviting social media users to go behi...\n",
              "                              ...                        \n",
              "3240    Finding billions of planets around other stars...\n",
              "3241    Newly-adapted imaging procedures allow researc...\n",
              "3242    RT @Space_Station: LIVE NOW: @Astro_Kanai, @As...\n",
              "3243    Meet the next three humans launching to @Space...\n",
              "3244    .@NASAEarth satellites saw the northern Califo...\n",
              "Name: full_text, Length: 3245, dtype: object"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df5 = df5['full_text']\n",
        "df5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>full_text</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>urls</th>\n",
              "      <th>created_at</th>\n",
              "      <th>favorite_count</th>\n",
              "      <th>retweet_count</th>\n",
              "      <th>source</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1013558869728071685</td>\n",
              "      <td>rt @nasa_johnson this week on houston we have ...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>Sun Jul 01 23:04:00 +0000 2018</td>\n",
              "      <td>0</td>\n",
              "      <td>96</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1013529203990581249</td>\n",
              "      <td>in this weeks stemonstation @astro_ricky demon...</td>\n",
              "      <td>['STEMonStation']</td>\n",
              "      <td>['https://youtu.be/34bFgA3H3hQ']</td>\n",
              "      <td>Sun Jul 01 21:06:07 +0000 2018</td>\n",
              "      <td>1587</td>\n",
              "      <td>429</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1013498567309348864</td>\n",
              "      <td>could these tiny electricityproducing bacteria...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['https://youtu.be/KhsCg7pmv0o']</td>\n",
              "      <td>Sun Jul 01 19:04:22 +0000 2018</td>\n",
              "      <td>1869</td>\n",
              "      <td>515</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1013486392134062080</td>\n",
              "      <td>rt @nasainterns ready to be part of the future...</td>\n",
              "      <td>['scientific']</td>\n",
              "      <td>[]</td>\n",
              "      <td>Sun Jul 01 18:16:00 +0000 2018</td>\n",
              "      <td>0</td>\n",
              "      <td>250</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1013477085279551488</td>\n",
              "      <td>weâre inviting social media users to go behind...</td>\n",
              "      <td>['TwilightZone']</td>\n",
              "      <td>['https://go.nasa.gov/2KFd8Ka']</td>\n",
              "      <td>Sun Jul 01 17:39:01 +0000 2018</td>\n",
              "      <td>1167</td>\n",
              "      <td>262</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3240</th>\n",
              "      <td>918229105706971137</td>\n",
              "      <td>finding billions of planets around other stars...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['http://go.nasa.gov/2xAmK3m']</td>\n",
              "      <td>Wed Oct 11 21:37:33 +0000 2017</td>\n",
              "      <td>2300</td>\n",
              "      <td>596</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3241</th>\n",
              "      <td>918198523610484737</td>\n",
              "      <td>newlyadapted imaging procedures allow research...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['http://go.nasa.gov/2kGGIDr']</td>\n",
              "      <td>Wed Oct 11 19:36:01 +0000 2017</td>\n",
              "      <td>1260</td>\n",
              "      <td>316</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3242</th>\n",
              "      <td>918177752473325568</td>\n",
              "      <td>rt @space_station live now @astro_kanai @astro...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>Wed Oct 11 18:13:29 +0000 2017</td>\n",
              "      <td>0</td>\n",
              "      <td>140</td>\n",
              "      <td>Twitter Web Client</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3243</th>\n",
              "      <td>918162536134037514</td>\n",
              "      <td>meet the next three humans launching to @space...</td>\n",
              "      <td>['askNASA']</td>\n",
              "      <td>['http://www.nasa.gov/live']</td>\n",
              "      <td>Wed Oct 11 17:13:01 +0000 2017</td>\n",
              "      <td>2252</td>\n",
              "      <td>506</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3244</th>\n",
              "      <td>918137015924854786</td>\n",
              "      <td>@nasaearth satellites saw the northern califor...</td>\n",
              "      <td>[]</td>\n",
              "      <td>['http://go.nasa.gov/2kHTSQE']</td>\n",
              "      <td>Wed Oct 11 15:31:37 +0000 2017</td>\n",
              "      <td>1400</td>\n",
              "      <td>548</td>\n",
              "      <td>Sprinklr</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3245 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                       id                                          full_text  \\\n",
              "0     1013558869728071685  rt @nasa_johnson this week on houston we have ...   \n",
              "1     1013529203990581249  in this weeks stemonstation @astro_ricky demon...   \n",
              "2     1013498567309348864  could these tiny electricityproducing bacteria...   \n",
              "3     1013486392134062080  rt @nasainterns ready to be part of the future...   \n",
              "4     1013477085279551488  weâre inviting social media users to go behind...   \n",
              "...                   ...                                                ...   \n",
              "3240   918229105706971137  finding billions of planets around other stars...   \n",
              "3241   918198523610484737  newlyadapted imaging procedures allow research...   \n",
              "3242   918177752473325568  rt @space_station live now @astro_kanai @astro...   \n",
              "3243   918162536134037514  meet the next three humans launching to @space...   \n",
              "3244   918137015924854786  @nasaearth satellites saw the northern califor...   \n",
              "\n",
              "               hashtags                              urls  \\\n",
              "0                    []                                []   \n",
              "1     ['STEMonStation']  ['https://youtu.be/34bFgA3H3hQ']   \n",
              "2                    []  ['https://youtu.be/KhsCg7pmv0o']   \n",
              "3        ['scientific']                                []   \n",
              "4      ['TwilightZone']   ['https://go.nasa.gov/2KFd8Ka']   \n",
              "...                 ...                               ...   \n",
              "3240                 []    ['http://go.nasa.gov/2xAmK3m']   \n",
              "3241                 []    ['http://go.nasa.gov/2kGGIDr']   \n",
              "3242                 []                                []   \n",
              "3243        ['askNASA']      ['http://www.nasa.gov/live']   \n",
              "3244                 []    ['http://go.nasa.gov/2kHTSQE']   \n",
              "\n",
              "                          created_at  favorite_count  retweet_count  \\\n",
              "0     Sun Jul 01 23:04:00 +0000 2018               0             96   \n",
              "1     Sun Jul 01 21:06:07 +0000 2018            1587            429   \n",
              "2     Sun Jul 01 19:04:22 +0000 2018            1869            515   \n",
              "3     Sun Jul 01 18:16:00 +0000 2018               0            250   \n",
              "4     Sun Jul 01 17:39:01 +0000 2018            1167            262   \n",
              "...                              ...             ...            ...   \n",
              "3240  Wed Oct 11 21:37:33 +0000 2017            2300            596   \n",
              "3241  Wed Oct 11 19:36:01 +0000 2017            1260            316   \n",
              "3242  Wed Oct 11 18:13:29 +0000 2017               0            140   \n",
              "3243  Wed Oct 11 17:13:01 +0000 2017            2252            506   \n",
              "3244  Wed Oct 11 15:31:37 +0000 2017            1400            548   \n",
              "\n",
              "                  source  \n",
              "0               Sprinklr  \n",
              "1               Sprinklr  \n",
              "2               Sprinklr  \n",
              "3               Sprinklr  \n",
              "4               Sprinklr  \n",
              "...                  ...  \n",
              "3240            Sprinklr  \n",
              "3241            Sprinklr  \n",
              "3242  Twitter Web Client  \n",
              "3243            Sprinklr  \n",
              "3244            Sprinklr  \n",
              "\n",
              "[3245 rows x 8 columns]"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "df5 = pd.read_csv('https://raw.githubusercontent.com/eleanorstrib/twitter_timeline_analysis_1/refs/heads/master/NASA_tweets.csv', encoding='latin-1')\n",
        "# Keep the original DataFrame and create a new Series for the 'full_text' column\n",
        "text_series = df5['full_text']  \n",
        "\n",
        "# Apply the cleaning function to the Series\n",
        "def limpiar_texto(text):\n",
        "    text = re.sub(r'[^\\w\\s\\@]', '', text.lower())\n",
        "    return text\n",
        "\n",
        "cleaned_text = text_series.apply(limpiar_texto)\n",
        "\n",
        "# Assign the cleaned text back to the 'full_text' column in the original DataFrame\n",
        "df5['full_text'] = cleaned_text \n",
        "df5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "def agregar_columna_sentimientos(texto):\n",
        "    palabras_positivas = ['good', 'ready', 'full', 'best', 'wonderful', 'delightful', 'excellent']\n",
        "    palabras_negativas = ['bad', 'worst', 'terrible', 'awful', 'disappointing', 'poor', 'hate']\n",
        "    \n",
        "    texto.lower()\n",
        "    puntaje_positivo = sum(palabra in texto for palabra in palabras_positivas)\n",
        "    puntaje_negativo = sum(palabra in texto for palabra in palabras_negativas)\n",
        "    \n",
        "    return 1 if puntaje_positivo > puntaje_negativo else 0 if puntaje_negativo > 0 else -1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_9140/1765546731.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df5['full_text'] = datos['Text'].apply(agregar_columna_sentimientos)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0            RT @NASA_Johnson: This week on \"Houston, We Ha...\n",
              "1            In this week's #STEMonStation, @astro_ricky de...\n",
              "2            Could these tiny, electricity-producing bacter...\n",
              "3            RT @NASAInterns: Ready to be part of the futur...\n",
              "4            Weâre inviting social media users to go behi...\n",
              "                                   ...                        \n",
              "3241         Newly-adapted imaging procedures allow researc...\n",
              "3242         RT @Space_Station: LIVE NOW: @Astro_Kanai, @As...\n",
              "3243         Meet the next three humans launching to @Space...\n",
              "3244         .@NASAEarth satellites saw the northern Califo...\n",
              "full_text    0      -1\n",
              "1      -1\n",
              "2      -1\n",
              "3      -1\n",
              "4     ...\n",
              "Name: full_text, Length: 3246, dtype: object"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df5['full_text'] = datos['Text'].apply(agregar_columna_sentimientos)\n",
        "df5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'sentimiento'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "File \u001b[0;32m~/Proyectos/talentoTech/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'sentimiento'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_train5, x_test5, y_train5, y_test5 \u001b[38;5;241m=\u001b[39m train_test_split(df5[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfull_text\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[43mdf5\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msentimiento\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
            "File \u001b[0;32m~/Proyectos/talentoTech/venv/lib/python3.12/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
            "File \u001b[0;32m~/Proyectos/talentoTech/venv/lib/python3.12/site-packages/pandas/core/series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
            "File \u001b[0;32m~/Proyectos/talentoTech/venv/lib/python3.12/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'sentimiento'"
          ]
        }
      ],
      "source": [
        "x_train5, x_test5, y_train5, y_test5 = train_test_split(df5['full_text'], df5['sentimiento'], test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'int' object has no attribute 'lower'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[77], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[1;32m      2\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvectorizador\u001b[39m\u001b[38;5;124m'\u001b[39m, CountVectorizer(stop_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124menglish\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[1;32m      3\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodelo_NB\u001b[39m\u001b[38;5;124m'\u001b[39m, MultinomialNB())\n\u001b[1;32m      4\u001b[0m ])\n\u001b[0;32m----> 6\u001b[0m \u001b[43mpipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train4\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train4\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m y_prediccion4 \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(x_test4)\n",
            "File \u001b[0;32m~/Proyectos/talentoTech/venv/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Proyectos/talentoTech/venv/lib/python3.12/site-packages/sklearn/pipeline.py:471\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Fit the model.\u001b[39;00m\n\u001b[1;32m    429\u001b[0m \n\u001b[1;32m    430\u001b[0m \u001b[38;5;124;03mFit all the transformers one after the other and sequentially transform the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[38;5;124;03m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    470\u001b[0m routed_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_method_params(method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, props\u001b[38;5;241m=\u001b[39mparams)\n\u001b[0;32m--> 471\u001b[0m Xt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPipeline\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_message(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m)):\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_final_estimator \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassthrough\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "File \u001b[0;32m~/Proyectos/talentoTech/venv/lib/python3.12/site-packages/sklearn/pipeline.py:408\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[0;34m(self, X, y, routed_params)\u001b[0m\n\u001b[1;32m    406\u001b[0m     cloned_transformer \u001b[38;5;241m=\u001b[39m clone(transformer)\n\u001b[1;32m    407\u001b[0m \u001b[38;5;66;03m# Fit or load from cache the current transformer\u001b[39;00m\n\u001b[0;32m--> 408\u001b[0m X, fitted_transformer \u001b[38;5;241m=\u001b[39m \u001b[43mfit_transform_one_cached\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcloned_transformer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPipeline\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_idx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrouted_params\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# Replace the transformer of the step with the fitted\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;66;03m# transformer. This is necessary when loading the transformer\u001b[39;00m\n\u001b[1;32m    419\u001b[0m \u001b[38;5;66;03m# from the cache.\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[step_idx] \u001b[38;5;241m=\u001b[39m (name, fitted_transformer)\n",
            "File \u001b[0;32m~/Proyectos/talentoTech/venv/lib/python3.12/site-packages/joblib/memory.py:312\u001b[0m, in \u001b[0;36mNotMemorizedFunc.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 312\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Proyectos/talentoTech/venv/lib/python3.12/site-packages/sklearn/pipeline.py:1303\u001b[0m, in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, X, y, weight, message_clsname, message, params)\u001b[0m\n\u001b[1;32m   1301\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _print_elapsed_time(message_clsname, message):\n\u001b[1;32m   1302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(transformer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit_transform\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m-> 1303\u001b[0m         res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfit_transform\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1305\u001b[0m         res \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfit\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\u001b[38;5;241m.\u001b[39mtransform(\n\u001b[1;32m   1306\u001b[0m             X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m   1307\u001b[0m         )\n",
            "File \u001b[0;32m~/Proyectos/talentoTech/venv/lib/python3.12/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Proyectos/talentoTech/venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1389\u001b[0m, in \u001b[0;36mCountVectorizer.fit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1381\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1382\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUpper case characters found in\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1383\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m vocabulary while \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlowercase\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1384\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m is True. These entries will not\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1385\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m be matched with any documents\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1386\u001b[0m             )\n\u001b[1;32m   1387\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m-> 1389\u001b[0m vocabulary, X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_vocab\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_documents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfixed_vocabulary_\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbinary:\n\u001b[1;32m   1392\u001b[0m     X\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mfill(\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[0;32m~/Proyectos/talentoTech/venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:1276\u001b[0m, in \u001b[0;36mCountVectorizer._count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m   1274\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m raw_documents:\n\u001b[1;32m   1275\u001b[0m     feature_counter \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m-> 1276\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m feature \u001b[38;5;129;01min\u001b[39;00m \u001b[43manalyze\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m   1277\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1278\u001b[0m             feature_idx \u001b[38;5;241m=\u001b[39m vocabulary[feature]\n",
            "File \u001b[0;32m~/Proyectos/talentoTech/venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:110\u001b[0m, in \u001b[0;36m_analyze\u001b[0;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m preprocessor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 110\u001b[0m         doc \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdoc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tokenizer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m         doc \u001b[38;5;241m=\u001b[39m tokenizer(doc)\n",
            "File \u001b[0;32m~/Proyectos/talentoTech/venv/lib/python3.12/site-packages/sklearn/feature_extraction/text.py:68\u001b[0m, in \u001b[0;36m_preprocess\u001b[0;34m(doc, accent_function, lower)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Chain together an optional series of text preprocessing steps to\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03mapply to a document.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    preprocessed string\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lower:\n\u001b[0;32m---> 68\u001b[0m     doc \u001b[38;5;241m=\u001b[39m \u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m()\n\u001b[1;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m accent_function \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m     doc \u001b[38;5;241m=\u001b[39m accent_function(doc)\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'lower'"
          ]
        }
      ],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('vectorizador', CountVectorizer(stop_words='english')),\n",
        "    ('modelo_NB', MultinomialNB())\n",
        "])\n",
        "\n",
        "pipeline.fit(x_train4, y_train4)\n",
        "y_prediccion4 = pipeline.predict(x_test4)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
